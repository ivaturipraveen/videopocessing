{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e08d9b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:04\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/lab4/.local/lib/python3.10/site-packages (1.26.1)\n",
      "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (9.0.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /home/lab4/.local/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.15.1-py3-none-any.whl (15 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.3.1\n",
      "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch) (1.9)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "Successfully installed filelock-3.15.1 fsspec-2024.6.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 opencv-python-4.10.0.84 torch-2.3.1 torchvision-0.18.1 triton-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python torch torchvision numpy pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b04e690d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lab4/Desktop/somu/yolov5\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gitpython>=3.1.30 in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.1.43)\n",
      "Requirement already satisfied: matplotlib>=3.3 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 6)) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.26.1)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=10.3.0 in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (10.3.0)\n",
      "Requirement already satisfied: psutil in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (5.9.8)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 11)) (5.4.1)\n",
      "Requirement already satisfied: requests>=2.32.0 in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 13)) (1.8.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (2.3.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.18.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (4.66.2)\n",
      "Requirement already satisfied: ultralytics>=8.2.34 in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (8.2.35)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 27)) (2.2.0)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 42)) (70.0.0)\n",
      "Requirement already satisfied: wheel>=0.38.0 in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 50)) (0.43.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/lab4/.local/lib/python3.10/site-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lab4/.local/lib/python3.10/site-packages (from requests>=2.32.0->-r requirements.txt (line 12)) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.0->-r requirements.txt (line 12)) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.0->-r requirements.txt (line 12)) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.32.0->-r requirements.txt (line 12)) (1.26.5)\n",
      "Requirement already satisfied: filelock in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.15.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2024.6.0)\n",
      "Requirement already satisfied: networkx in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.0.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.20.5)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.9)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/lab4/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->-r requirements.txt (line 15)) (12.5.40)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/lab4/.local/lib/python3.10/site-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (2.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/lab4/.local/lib/python3.10/site-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/lab4/.local/lib/python3.10/site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/lab4/.local/lib/python3.10/site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2.8.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/lab4/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.4->-r requirements.txt (line 27)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5\n",
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3de75df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/lab4/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/lab4/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/lab4/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames from /home/lab4/Desktop/somu/video.mp4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracted: 1433/1433: 100%|████████████████| 1433/1433 [00:01<00:00, 770.26it/s]\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames extracted: 1433\n",
      "Enter your query: jewellery\n",
      "Meaningful words extracted from query: ['jewellery']\n",
      "No frames containing the queried object(s) 'jewellery' found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Add YOLOv5 directory to path\n",
    "sys.path.append(r'/content/yolov5')\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.general import non_max_suppression, scale_boxes, check_img_size  # Note: Check latest utility functions\n",
    "from utils.augmentations import letterbox\n",
    "\n",
    "# YOLOv5 predefined classes\n",
    "YOLOV5_CLASSES = {\n",
    "    0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', \n",
    "    6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', \n",
    "    11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', \n",
    "    16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', \n",
    "    22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', \n",
    "    27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', \n",
    "    32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', \n",
    "    36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', \n",
    "    40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', \n",
    "    46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', \n",
    "    51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', \n",
    "    57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', \n",
    "    62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', \n",
    "    67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', \n",
    "    72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', \n",
    "    77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'\n",
    "}\n",
    "\n",
    "def preprocess_query(query):\n",
    "    words = word_tokenize(query.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    interrogative_terms = {'who', 'what', 'where', 'when', 'why', 'how', 'find'}\n",
    "    meaningful_words = []\n",
    "    for word, tag in pos_tag(words):\n",
    "        if word not in stop_words and word not in interrogative_terms and (tag.startswith('N') or tag.startswith('V')):\n",
    "            meaningful_words.append(word)\n",
    "    return meaningful_words\n",
    "\n",
    "def extract_frames(video_path, output_folder):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    print(f\"Extracting frames from {video_path}...\")\n",
    "    progress_step = max(total_frames // 10, 1)\n",
    "    pbar = tqdm(total=total_frames)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_path = os.path.join(output_folder, f\"frame_{count:04d}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        count += 1\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(f\"Extracted: {count}/{total_frames}\")\n",
    "\n",
    "    pbar.close()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return count\n",
    "\n",
    "def detect_objects_yolo(frame_path, model, device, meaningful_words):\n",
    "    img = cv2.imread(frame_path)\n",
    "    img0 = img.copy()\n",
    "    img = letterbox(img, 640, stride=32, auto=True)[0]\n",
    "    img = img.transpose((2, 0, 1))[::-1]\n",
    "    img = np.ascontiguousarray(img)\n",
    "\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = img.float()\n",
    "    img /= 255.0\n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(img, augment=False)\n",
    "    pred = non_max_suppression(pred, 0.25, 0.45, classes=None, agnostic=False)\n",
    "\n",
    "    detected_meaningful_frames = []\n",
    "\n",
    "    for det in pred:\n",
    "        if det is not None and len(det):\n",
    "            det[:, :4] = scale_boxes(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "            labels = det[:, -1].cpu().numpy()\n",
    "            label_names = [model.names[int(label)] for label in labels]\n",
    "\n",
    "            found_words = set()\n",
    "            for word in meaningful_words:\n",
    "                for i, name in enumerate(label_names):\n",
    "                    if word in name.lower():\n",
    "                        xyxy = det[i, :4]\n",
    "                        c1, c2 = (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3]))\n",
    "                        cv2.rectangle(img0, c1, c2, (255, 0, 0), 2)\n",
    "                        found_words.add(word)\n",
    "            if len(found_words) == len(meaningful_words):\n",
    "                detected_meaningful_frames.append(frame_path)\n",
    "\n",
    "    return detected_meaningful_frames, img0\n",
    "\n",
    "def main(video_path, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    frame_count = extract_frames(video_path, output_folder)\n",
    "    print(f\"Total frames extracted: {frame_count}\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = DetectMultiBackend('yolov5s.pt', device=device)\n",
    "    model.eval()\n",
    "\n",
    "    query = input(\"Enter your query: \")\n",
    "\n",
    "    meaningful_words = preprocess_query(query)\n",
    "    print(f\"Meaningful words extracted from query: {meaningful_words}\")\n",
    "\n",
    "    queried_frames_folder = os.path.join(os.path.dirname(output_folder), \"_\".join(meaningful_words))\n",
    "    os.makedirs(queried_frames_folder, exist_ok=True)\n",
    "\n",
    "    frame_files = sorted([f for f in os.listdir(output_folder) if f.endswith('.jpg')])\n",
    "    queried_frames = []\n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(output_folder, frame_file)\n",
    "        detected_frames, img0 = detect_objects_yolo(frame_path, model, device, meaningful_words)\n",
    "\n",
    "        if detected_frames:\n",
    "            queried_frame_path = os.path.join(queried_frames_folder, os.path.basename(frame_path))\n",
    "            cv2.imwrite(queried_frame_path, img0)\n",
    "            queried_frames.extend(detected_frames)\n",
    "\n",
    "    if not queried_frames:\n",
    "        print(f\"No frames containing the queried object(s) '{query}' found.\")\n",
    "        return\n",
    "\n",
    "    queried_frames.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[-1]))\n",
    "\n",
    "    first_frame = cv2.imread(queried_frames[0])\n",
    "    height, width, channels = first_frame.shape\n",
    "\n",
    "    video_output_path = os.path.join(output_folder, f'output_video_{query}.mp4')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(video_output_path, fourcc, 25.0, (width, height))\n",
    "\n",
    "    for frame_path in queried_frames:\n",
    "        frame = cv2.imread(frame_path)\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Video created: {video_output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = r'/home/lab4/Desktop/somu/video.mp4'\n",
    "    output_folder = r'/home/lab4/Desktop/somu/frames'\n",
    "    main(video_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f1bf6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lab4/CenterNet\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (4.10.0.84)\n",
      "Requirement already satisfied: Cython in /home/lab4/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (3.0.10)\n",
      "Collecting numba\n",
      "  Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting progress\n",
      "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from -r requirements.txt (line 5)) (3.5.1)\n",
      "Collecting easydict\n",
      "  Downloading easydict-1.13-py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from -r requirements.txt (line 7)) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /home/lab4/.local/lib/python3.10/site-packages (from opencv-python->-r requirements.txt (line 1)) (1.23.5)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0\n",
      "  Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: progress\n",
      "  Building wheel for progress (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for progress: filename=progress-1.6-py3-none-any.whl size=9614 sha256=8432d3815a5b2a65d4cd6e47af9bd794b91be271f12b741e6aad7f7155661dbd\n",
      "  Stored in directory: /home/lab4/.cache/pip/wheels/a2/68/5f/c339b20a41659d856c93ccdce6a33095493eb82c3964aac5a1\n",
      "Successfully built progress\n",
      "Installing collected packages: progress, easydict, llvmlite, numba\n",
      "Successfully installed easydict-1.13 llvmlite-0.43.0 numba-0.60.0 progress-1.6\n"
     ]
    }
   ],
   "source": [
    "%cd /home/lab4/CenterNet\n",
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "543db666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yolo v8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4043254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ultralytics in /home/lab4/.local/lib/python3.10/site-packages (8.2.35)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/lib/python3/dist-packages (from ultralytics) (5.4.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/lab4/.local/lib/python3.10/site-packages (from ultralytics) (2.2.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/lab4/.local/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/lab4/.local/lib/python3.10/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/lab4/.local/lib/python3.10/site-packages (from ultralytics) (2.3.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/lab4/.local/lib/python3.10/site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/lib/python3/dist-packages (from ultralytics) (1.8.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/lab4/.local/lib/python3.10/site-packages (from ultralytics) (0.18.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/lab4/.local/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/lab4/.local/lib/python3.10/site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/lab4/.local/lib/python3.10/site-packages (from ultralytics) (4.66.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/lib/python3/dist-packages (from ultralytics) (3.5.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /home/lab4/.local/lib/python3.10/site-packages (from ultralytics) (1.23.5)\n",
      "Requirement already satisfied: psutil in /home/lab4/.local/lib/python3.10/site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/lab4/.local/lib/python3.10/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.1.4->ultralytics) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/lab4/.local/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/lab4/.local/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.23.0->ultralytics) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.23.0->ultralytics) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.23.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lab4/.local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
      "Requirement already satisfied: filelock in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.15.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: networkx in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.8.0->ultralytics) (3.0.3)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch>=1.8.0->ultralytics) (1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/lab4/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.8.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/lab4/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.5.40)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.4->ultralytics) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f0c1abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lab4/ultralytics\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Processing /home/lab4/ultralytics\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: UNKNOWN\n",
      "  Building wheel for UNKNOWN (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for UNKNOWN: filename=UNKNOWN-0.0.0-py3-none-any.whl size=12921 sha256=a1ff570ebbb9f65dcbfabc28ef91ab9242b0b3daa93eff0e9cb933c51d1910b7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sv_w1by3/wheels/17/ee/20/8d89980f9064034f534d6332354ca177cae72e27597ed665e0\n",
      "Successfully built UNKNOWN\n",
      "Installing collected packages: UNKNOWN\n",
      "Successfully installed UNKNOWN-0.0.0\n"
     ]
    }
   ],
   "source": [
    "%cd /home/lab4/ultralytics\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fe82419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/lab4/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/lab4/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/lab4/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames from /home/lab4/Desktop/somu/video.mp4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1433/1433 [00:01<00:00, 935.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames extracted: 1433\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'yolov8s.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████| 21.5M/21.5M [00:02<00:00, 7.88MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=coco.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "\n",
      "Dataset 'coco.yaml' images not found ⚠️, missing path '/home/lab4/Desktop/somu/yolov5/datasets/coco/val2017.txt'\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017labels-segments.zip to '/home/lab4/Desktop/somu/yolov5/datasets/coco2017labels-segments.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 169M/169M [00:15<00:00, 11.1MB/s]\n",
      "Unzipping /home/lab4/Desktop/somu/yolov5/datasets/coco2017labels-segments.zip to"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://images.cocodataset.org/zips/val2017.zip to '/home/lab4/Desktop/somu/yolov5/datasets/coco/images/val2017.zip'...\n",
      "Downloading http://images.cocodataset.org/zips/train2017.zip to '/home/lab4/Desktop/somu/yolov5/datasets/coco/images/train2017.zip'...\n",
      "Downloading http://images.cocodataset.org/zips/test2017.zip to '/home/lab4/Desktop/somu/yolov5/datasets/coco/images/test2017.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_56981/1146926720.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'/home/lab4/Desktop/somu/video.mp4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0moutput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'/home/lab4/Desktop/somu/frames'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_56981/1146926720.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(video_path, output_folder)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov8s.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your query: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2447\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m         \"\"\"\n\u001b[0;32m-> 2449\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2451\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ultralytics/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# manually set model only if not resuming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ultralytics/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# Model and Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_model_file_from_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ultralytics/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0;34m\"obb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             }:\n\u001b[0;32m--> 522\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_det_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"yaml_file\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"yaml_file\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# for validating 'yolo train data=url.zip' usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ultralytics/ultralytics/data/utils.py\u001b[0m in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# python script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"yaml\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"({round(time.time() - t, 1)}s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"success ✅ {dt}, saved to {colorstr('bold', DATASETS_DIR)}\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mf\"failure {dt} ❌\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/ultralytics/ultralytics/utils/downloads.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, dir, unzip, delete, curl, threads, retry, exist_ok)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mthreads\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             pool.map(\n\u001b[0m\u001b[1;32m    484\u001b[0m                 lambda x: safe_download(\n\u001b[1;32m    485\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         '''\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Ensure you have the necessary NLTK resources downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# YOLOv8 predefined classes\n",
    "YOLOV8_CLASSES = [\n",
    "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',\n",
    "    'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
    "    'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',\n",
    "    'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
    "    'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush'\n",
    "]\n",
    "\n",
    "def preprocess_query(query):\n",
    "    words = word_tokenize(query.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    meaningful_phrases = []\n",
    "\n",
    "    grammar = r\"\"\"\n",
    "        NP: {<DT>?<JJ>*<NN>}  # NP: optional determiner, adjectives, and noun\n",
    "            {<NNP>+}          # NP: sequence of proper nouns\n",
    "    \"\"\"\n",
    "    chunk_parser = nltk.RegexpParser(grammar)\n",
    "    tagged_words = pos_tag(words)\n",
    "    chunked_words = chunk_parser.parse(tagged_words)\n",
    "\n",
    "    for subtree in chunked_words.subtrees(filter=lambda t: t.label() == 'NP'):\n",
    "        phrase = ' '.join(word for word, tag in subtree.leaves())\n",
    "        meaningful_phrases.append(phrase)\n",
    "\n",
    "    return meaningful_phrases\n",
    "\n",
    "def extract_frames(video_path, output_folder):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    print(f\"Extracting frames from {video_path}...\")\n",
    "    pbar = tqdm(total=total_frames)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_path = os.path.join(output_folder, f\"frame_{count:04d}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        count += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return count\n",
    "\n",
    "def detect_objects_yolo(frame_path, model, device, meaningful_phrases):\n",
    "    img = cv2.imread(frame_path)\n",
    "    results = model(img)\n",
    "\n",
    "    detected_meaningful_frames = []\n",
    "    label_names = [YOLOV8_CLASSES[int(cls)] for cls in results[0].boxes.cls]\n",
    "\n",
    "    for phrase in meaningful_phrases:\n",
    "        if all(word in \" \".join(label_names).lower() for word in phrase.split()):\n",
    "            for box in results[0].boxes:\n",
    "                c1, c2 = (int(box.xyxy[0]), int(box.xyxy[1])), (int(box.xyxy[2]), int(box.xyxy[3]))\n",
    "                cv2.rectangle(img, c1, c2, (255, 0, 0), 2)\n",
    "            detected_meaningful_frames.append(frame_path)\n",
    "            break\n",
    "\n",
    "    return detected_meaningful_frames, img\n",
    "\n",
    "def main(video_path, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    frame_count = extract_frames(video_path, output_folder)\n",
    "    print(f\"Total frames extracted: {frame_count}\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = YOLO('yolov8s.pt')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    query = input(\"Enter your query: \")\n",
    "\n",
    "    meaningful_phrases = preprocess_query(query)\n",
    "    print(f\"Meaningful phrases extracted from query: {meaningful_phrases}\")\n",
    "\n",
    "    queried_frames_folder = os.path.join(os.path.dirname(output_folder), \"_\".join(meaningful_phrases))\n",
    "    os.makedirs(queried_frames_folder, exist_ok=True)\n",
    "\n",
    "    frame_files = sorted([f for f in os.listdir(output_folder) if f.endswith('.jpg')])\n",
    "    queried_frames = []\n",
    "    pbar = tqdm(total=len(frame_files))\n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(output_folder, frame_file)\n",
    "        detected_frames, img = detect_objects_yolo(frame_path, model, device, meaningful_phrases)\n",
    "\n",
    "        if detected_frames:\n",
    "            queried_frame_path = os.path.join(queried_frames_folder, os.path.basename(frame_path))\n",
    "            cv2.imwrite(queried_frame_path, img)\n",
    "            queried_frames.extend(detected_frames)\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    if not queried_frames:\n",
    "        print(f\"No frames containing the queried object(s) '{query}' found.\")\n",
    "        return\n",
    "\n",
    "    queried_frames.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[-1]))\n",
    "\n",
    "    first_frame = cv2.imread(queried_frames[0])\n",
    "    height, width, channels = first_frame.shape\n",
    "\n",
    "    video_output_path = os.path.join(output_folder, f'output_video_{query}.mp4')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(video_output_path, fourcc, 25.0, (width, height))\n",
    "\n",
    "    for frame_path in queried_frames:\n",
    "        frame = cv2.imread(frame_path)\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Video created: {video_output_path}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = r'/home/lab4/Desktop/somu/video.mp4'\n",
    "    output_folder = r'/home/lab4/Desktop/somu/frames'\n",
    "    main(video_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5421eb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/lab4/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/lab4/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/lab4/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models.yolo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_56981/398469926.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Add YOLOv8 directory to path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/content/yolov8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneral\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnon_max_suppression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_coords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models.yolo'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Add YOLOv8 directory to path\n",
    "sys.path.append(r'/content/yolov8')\n",
    "from models.yolo import model\n",
    "from utils.general import non_max_suppression, scale_coords\n",
    "\n",
    "# YOLOv8 predefined classes\n",
    "YOLOV8_CLASSES = [\n",
    "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',\n",
    "    'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
    "    'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',\n",
    "    'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
    "    'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush'\n",
    "]\n",
    "\n",
    "def preprocess_query(query):\n",
    "    words = word_tokenize(query.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    interrogative_terms = {'who', 'what', 'where', 'when', 'why', 'how', 'find'}\n",
    "    meaningful_words = []\n",
    "    for word, tag in pos_tag(words):\n",
    "        if word not in stop_words and word not in interrogative_terms and (tag.startswith('N') or tag.startswith('V')):\n",
    "            meaningful_words.append(word)\n",
    "    return meaningful_words\n",
    "\n",
    "def extract_frames(video_path, output_folder):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    print(f\"Extracting frames from {video_path}...\")\n",
    "    progress_step = max(total_frames // 10, 1)\n",
    "    pbar = tqdm(total=total_frames)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_path = os.path.join(output_folder, f\"frame_{count:04d}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        count += 1\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(f\"Extracted: {count}/{total_frames}\")\n",
    "\n",
    "    pbar.close()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return count\n",
    "\n",
    "def detect_objects_yolov8(frame_path, model, device, meaningful_words):\n",
    "    img = cv2.imread(frame_path)\n",
    "    img0 = img.copy()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = letterbox(img, new_shape=(640, 640))[0]\n",
    "    img = img.transpose((2, 0, 1))[::-1]\n",
    "    img = np.ascontiguousarray(img)\n",
    "\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = img.float()  # Ensure data type is float\n",
    "    img /= 255.0  # Normalize to 0-1\n",
    "\n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(img)[0]\n",
    "\n",
    "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False)\n",
    "\n",
    "    detected_meaningful_frames = []\n",
    "\n",
    "    for det in pred:\n",
    "        if det is not None and len(det):\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "            labels = det[:, -1].cpu().numpy().astype(int)\n",
    "            label_names = [YOLOV8_CLASSES[label] for label in labels]\n",
    "\n",
    "            found_words = set()\n",
    "            for word in meaningful_words:\n",
    "                for i, name in enumerate(label_names):\n",
    "                    if word in name.lower():\n",
    "                        box = det[i, :4]\n",
    "                        c1, c2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))\n",
    "                        cv2.rectangle(img0, c1, c2, (255, 0, 0), 2)\n",
    "                        found_words.add(word)\n",
    "            if len(found_words) == len(meaningful_words):\n",
    "                detected_meaningful_frames.append(frame_path)\n",
    "\n",
    "    return detected_meaningful_frames, img0\n",
    "\n",
    "def main(video_path, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    frame_count = extract_frames(video_path, output_folder)\n",
    "    print(f\"Total frames extracted: {frame_count}\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = YOLOv8()  # Instantiate YOLOv8 model\n",
    "    model.load_state_dict(torch.load('yolov8.pt', map_location=device)['model'])\n",
    "    model.to(device).eval()\n",
    "\n",
    "    query = input(\"Enter your query: \")\n",
    "\n",
    "    meaningful_words = preprocess_query(query)\n",
    "    print(f\"Meaningful words extracted from query: {meaningful_words}\")\n",
    "\n",
    "    queried_frames_folder = os.path.join(os.path.dirname(output_folder), \"_\".join(meaningful_words))\n",
    "    os.makedirs(queried_frames_folder, exist_ok=True)\n",
    "\n",
    "    frame_files = sorted([f for f in os.listdir(output_folder) if f.endswith('.jpg')])\n",
    "    queried_frames = []\n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(output_folder, frame_file)\n",
    "        detected_frames, img0 = detect_objects_yolov8(frame_path, model, device, meaningful_words)\n",
    "\n",
    "        if detected_frames:\n",
    "            queried_frame_path = os.path.join(queried_frames_folder, os.path.basename(frame_path))\n",
    "            cv2.imwrite(queried_frame_path, img0)\n",
    "            queried_frames.extend(detected_frames)\n",
    "\n",
    "    if not queried_frames:\n",
    "        print(f\"No frames containing the queried object(s) '{query}' found.\")\n",
    "        return\n",
    "\n",
    "    queried_frames.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[-1]))\n",
    "\n",
    "    first_frame = cv2.imread(queried_frames[0])\n",
    "    height, width, channels = first_frame.shape\n",
    "\n",
    "    video_output_path = os.path.join(output_folder, f'output_video_{query}.mp4')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(video_output_path, fourcc, 25.0, (width, height))\n",
    "\n",
    "    for frame_path in queried_frames:\n",
    "        frame = cv2.imread(frame_path)\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Video created: {video_output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = r'/home/lab4/Desktop/somu/video.mp4'\n",
    "    output_folder = r'/home/lab4/Desktop/somu/frames'\n",
    "    main(video_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d369e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
